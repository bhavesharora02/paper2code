# papers.yaml
# A small paper matrix for Week 1 (3 diverse papers: CV, NLP, Classical ML).
# Put the corresponding PDFs into the `samples/` folder with the filenames below.

papers:
  - id: cv_vit
    title: "An Image is Worth 16x16 Words: Vision Transformer"
    source: "arXiv:2010.11929"
    domain: "cv"
    pdf: "samples/vit_arxiv_2010.11929.pdf"
    dataset_fallback:
      name: "imagenet-subset"
      note: "Use CIFAR or FakeData for smoke tests."

  - id: nlp_bert
    title: "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"
    source: "arXiv:1810.04805"
    domain: "nlp"
    pdf: "samples/bert_arxiv_1810.04805.pdf"
    expected_metrics:
      key: "accuracy"
      target: 0.90
      tolerance_pct: 3.0
    dataset_fallback:
      name: "glue-sst2"
      note: "Use HF datasets or FakeData for smoke tests."

  - id: ml_xgb
    title: "XGBoost: A Scalable Tree Boosting System"
    source: "arXiv:1603.02754"
    domain: "ml"
    pdf: "samples/xgboost_arxiv_1603.02754.pdf"
    expected_metrics:
      key: "accuracy"
      target: 0.85
      tolerance_pct: 3.0
    dataset_fallback:
      name: "uci_credit"
      note: "Use a small public tabular dataset or FakeData for smoke tests."
